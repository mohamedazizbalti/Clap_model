# Respiratory Sound Classification using CLAP

This repository contains a multimodal machine learning system that classifies respiratory anomalies (e.g., wheezes, crackles) from lung sound recordings and associated patient metadata. It uses the CLAP (Contrastive Language-Audio Pretraining) architecture for joint audio-text embedding, with deployment via FastAPI.

---

## ğŸš€ Project Overview

This project addresses the limitations of traditional respiratory diagnosis by combining:
- **Microphone-recorded audio** of lung sounds.
- **Clinical notes extracted from PDFs** (e.g., symptoms, history).

A hybrid pipeline embeds these inputs via a pretrained CLAP model and predicts respiratory sound categories. The results are then passed to a downstream Large Language Model (LLM) with RAG capabilities for high-level clinical reasoning and conversational assistance.

---

## ğŸ§  Features

- ğŸ“¼ Audio classification (normal, wheeze, crackle, both)
- ğŸ“ Metadata ingestion from PDFs (patient notes, symptoms)
- ğŸ¤– Multimodal CLAP embedding
- ğŸ©º Integration with an LLM-based medical assistant (RAG-enhanced)
- ğŸŒ FastAPI deployment (upload `.wav` + `.pdf`, receive prediction + diagnostic insight)
- ğŸ“± Mobile-first use case (microphone input compatible)

